{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import ndarrays_to_parameters, Context\n",
    "from flwr.server import ServerApp, ServerConfig\n",
    "from flwr.server import ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.common import Metrics, NDArrays, Scalar\n",
    "from typing import List, Tuple, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize to [0, 1]\n",
    "x_train = x_train.reshape(-1, 28 * 28)  # Flatten images\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def exclude_digits(x_data, y_data, excluded_digits):\n",
    "    mask = ~np.isin(y_data, excluded_digits)  # Create a mask for non-excluded digits\n",
    "    x_filtered = x_data[mask]  # Filter input data\n",
    "    y_filtered = y_data[mask]  # Filter labels\n",
    "    return x_filtered, y_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_1 :  {0, 2, 4, 5, 6, 8, 9}\n",
      "y_train_2 :  {0, 1, 3, 4, 6, 7, 9}\n",
      "y_train_3 :  {0, 1, 2, 3, 5, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "x_train_1, y_train_1  = exclude_digits(x_train, y_train, excluded_digits=[1, 3, 7])\n",
    "print(\"y_train_1 : \",set(y_train_1))\n",
    "\n",
    "\n",
    "x_train_2, y_train_2 = exclude_digits(x_train, y_train, excluded_digits=[2, 5, 8])\n",
    "print(\"y_train_2 : \",set(y_train_2))\n",
    "\n",
    "x_train_3, y_train_3 = exclude_digits(x_train, y_train, excluded_digits=[4, 6, 9])\n",
    "print(\"y_train_3 : \",set(y_train_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [(x_train_1, y_train_1 ),(x_train_2, y_train_2),(x_train_3, y_train_3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_1 :  {0, 2, 4, 5, 6, 8, 9}\n",
      "y_test_2 :  {0, 1, 3, 4, 6, 7, 9}\n",
      "y_test_3 :  {0, 1, 2, 3, 5, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "x_test_1, y_test_1  = exclude_digits(x_test, y_test, excluded_digits=[1, 3, 7])\n",
    "print(\"y_test_1 : \",set(y_test_1))\n",
    "\n",
    "x_test_2, y_test_2  = exclude_digits(x_test, y_test, excluded_digits=[2, 5, 8])\n",
    "print(\"y_test_2 : \",set(y_test_2))\n",
    "\n",
    "x_test_3, y_test_3  = exclude_digits(x_test, y_test, excluded_digits=[4,6,9])\n",
    "print(\"y_test_3 : \",set(y_test_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = [(x_test_1, y_test_1),(x_test_2, y_test_2),(x_test_3, y_test_3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model training\n",
    "- Sample model\n",
    "- training method\n",
    "- Evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,pth_x,pth_y):\n",
    "    batch_size = 64\n",
    "    epochs = 20\n",
    "    num_batches = len(pth_x) // batch_size\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    pth_y_onehot = tf.keras.utils.to_categorical(pth_y, num_classes=10)\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        for i in range(num_batches):\n",
    "            # Get a batch of data\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            x_batch = pth_x[start:end]\n",
    "            y_batch = pth_y_onehot[start:end]\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(x_batch, training=True)  # Forward pass\n",
    "                loss = loss_fn(y_batch, predictions)        # Compute loss\n",
    "            \n",
    "\n",
    "            gradients = tape.gradient(loss, model.trainable_variables) \n",
    "        \n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # Update weights\n",
    "\n",
    "            if i % 200 == 0:  # Print progress every 200 batches\n",
    "                print(f\"Batch {i}/{num_batches}, Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,x_test,y_test):\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss = loss_fn(y_test_onehot, model(x_test))\n",
    "    print(\"test_loss : \",test_loss)\n",
    "    test_accuracy = tf.keras.metrics.categorical_accuracy(y_test_onehot, model(x_test))\n",
    "    print(\"test_accuracy : \",test_accuracy)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainset, testset):\n",
    "        self.net = net\n",
    "        self.trainset = trainset\n",
    "        self.testset = testset\n",
    "\n",
    "    # Train the model\n",
    "    def fit(self, parameters, config):\n",
    "        self.net.set_weights(parameters)\n",
    "        pth_x,pth_y = self.trainset # (x,y)\n",
    "        train_model(self.net,pth_x,pth_y )\n",
    "        return self.net.get_weights(), len(pth_y), {}\n",
    "\n",
    "    # Test the model\n",
    "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
    "        self.net.set_weights(parameters)\n",
    "        loss, accuracy = evaluate_model(self.net, self.testset)\n",
    "        return loss, len(self.testset), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client function\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = SimpleNN()\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    client_train = train_sets[int(partition_id)]\n",
    "    client_test = test_sets[int(partition_id)]\n",
    "    return FlowerClient(net, client_train, client_test).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ClientApp(client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 23:07:20.853120: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-06-06 23:07:20.853398: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-06-06 23:07:20.853406: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749226040.853430 9868729 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1749226040.853484 9868729 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss :  tf.Tensor(2.4357412, shape=(), dtype=float32)\n",
      "test_accuracy :  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(6827,), dtype=float32)\n",
      "test accuracy on [1,3,7]:  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(6827,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test code \n",
    "net = SimpleNN()\n",
    "_, accuracy137 = evaluate_model(net, x_test_1,y_test_1)\n",
    "print(\"test accuracy on [1,3,7]: \", accuracy137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluate for model testing\n",
    "- The evaluate method evaluates the performance of the neural network model using the provided parameters and the test dataset (testset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(server_round, parameters, config):\n",
    "    net = SimpleNN()\n",
    "    net.set_weights(parameters)\n",
    "\n",
    "    _, accuracy137 = evaluate_model(net, x_test_1,y_test_1)\n",
    "    _, accuracy258 = evaluate_model(net, x_test_2,y_test_2)\n",
    "    _, accuracy469 = evaluate_model(net, x_test_3,y_test_3)\n",
    "\n",
    "    print(\"test accuracy on [1,3,7]: \", accuracy137)\n",
    "    print(\"test accuracy on [2,5,8]: \", accuracy258)\n",
    "    print(\"test accuracy on [4,6,9]: \", accuracy469)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The federated averaging strategy (`strategy.FedAvg`) is created for federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNN()\n",
    "params = ndarrays_to_parameters(net.get_weights())\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.0,\n",
    "        initial_parameters=params,\n",
    "        evaluate_fn=evaluate,\n",
    "    )\n",
    "    config=ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(\n",
    "        strategy=strategy,\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import ERROR\n",
    "backend_setup = {\"init_args\": {\"logging_level\": ERROR, \"log_to_driver\": False}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss :  tf.Tensor(2.429636, shape=(), dtype=float32)\n",
      "test_accuracy :  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(6827,), dtype=float32)\n",
      "test_loss :  tf.Tensor(2.4564862, shape=(), dtype=float32)\n",
      "test_accuracy :  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(7102,), dtype=float32)\n",
      "test_loss :  tf.Tensor(2.3757248, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy :  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(7051,), dtype=float32)\n",
      "test accuracy on [1,3,7]:  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(6827,), dtype=float32)\n",
      "test accuracy on [2,5,8]:  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(7102,), dtype=float32)\n",
      "test accuracy on [4,6,9]:  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(7051,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m 2025-06-06 23:07:36.802373: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m 2025-06-06 23:07:36.802555: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m 2025-06-06 23:07:36.802562: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m I0000 00:00:1749226056.802578 9870249 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m I0000 00:00:1749226056.802608 9870249 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 1/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 0/660, Loss: 2.1752\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 1/20\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 200/668, Loss: 0.2334\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 600/660, Loss: 0.1795\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 2/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 0/638, Loss: 0.1496\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 2/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 400/668, Loss: 0.0970\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 3/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 0/668, Loss: 0.0405\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 3/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 200/638, Loss: 0.0137\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 4/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 0/660, Loss: 0.0141\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 4/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 200/668, Loss: 0.0742\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 600/660, Loss: 0.0268\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 5/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 200/660, Loss: 0.0083\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 5/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 400/668, Loss: 0.0311\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 6/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 0/638, Loss: 0.0702\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 6/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 400/660, Loss: 0.0150\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 7/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 600/660, Loss: 0.0088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 7/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 200/638, Loss: 0.0062\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 400/668, Loss: 0.0101\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 8/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 0/668, Loss: 0.0130\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 8/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 400/660, Loss: 0.0095\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 9/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 0/660, Loss: 0.0113\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 9/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 200/668, Loss: 0.0119\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 600/638, Loss: 0.0181\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 10/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 200/668, Loss: 0.0090\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 10/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 600/660, Loss: 0.0019\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 11/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 200/638, Loss: 0.0017\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 11/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 400/668, Loss: 0.0022\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 12/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 12/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 0/668, Loss: 0.0090\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 12/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 400/668, Loss: 0.0013\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 13/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 200/638, Loss: 0.0016\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 13/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 600/638, Loss: 0.0057\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 14/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 0/668, Loss: 0.0031\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 14/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 600/638, Loss: 0.0084\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 15/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 0/668, Loss: 0.0042\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 15/20\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 600/638, Loss: 0.0258\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 16/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 200/638, Loss: 0.0007\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 16/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 16/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 400/660, Loss: 0.0020\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 17/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 400/668, Loss: 0.0004\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 17/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 17/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 400/638, Loss: 0.0007\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 18/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 0/638, Loss: 0.0154\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 18/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 600/668, Loss: 0.0049\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 18/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 200/668, Loss: 0.0003\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 19/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 19/20\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Batch 200/638, Loss: 0.0001\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 19/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 400/660, Loss: 0.0005\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m Epoch 20/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 0/660, Loss: 0.0000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Epoch 20/20\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Epoch 20/20\n",
      "\u001b[36m(ClientAppActor pid=62573)\u001b[0m Batch 400/660, Loss: 0.0004\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 400/668, Loss: 0.0000\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: You called `set_weights(weights)` on layer 'simple_nn_1' with a weight list of length 4, but the layer was expecting 0 weights.\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/compat/app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/server.py\", line 128, in fit\n",
      "    res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/strategy/fedavg.py\", line 167, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
      "  File \"/var/folders/xd/3z5vvpds0zxf_pypxd4cn3d80000gn/T/ipykernel_62480/783575536.py\", line 3, in evaluate\n",
      "    net.set_weights(parameters)\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 702, in set_weights\n",
      "    raise ValueError(\n",
      "ValueError: You called `set_weights(weights)` on layer 'simple_nn_1' with a weight list of length 4, but the layer was expecting 0 weights.\n",
      "\n",
      "Exception in thread Thread-4 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/compat/app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/server.py\", line 128, in fit\n",
      "    res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/server/strategy/fedavg.py\", line 167, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
      "  File \"/var/folders/xd/3z5vvpds0zxf_pypxd4cn3d80000gn/T/ipykernel_62480/783575536.py\", line 3, in evaluate\n",
      "  File \"/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 702, in set_weights\n",
      "    raise ValueError(\n",
      "ValueError: You called `set_weights(weights)` on layer 'simple_nn_1' with a weight list of length 4, but the layer was expecting 0 weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=62572)\u001b[0m Batch 600/668, Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m 2025-06-06 23:07:39.688440: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m 2025-06-06 23:07:39.688486: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m 2025-06-06 23:07:39.688492: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m I0000 00:00:1749226059.688505 9870246 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=62574)\u001b[0m I0000 00:00:1749226059.688534 9870246 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initiate the simulation passing the server and client apps\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Specify the number of super nodes that will be selected on every round\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#backend_config=backend_setup,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/simulation/run_simulation.py:211\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_tf_gpu_growth:\n\u001b[1;32m    203\u001b[0m     warn_deprecated_feature_with_example(\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `enable_tf_gpu_growth=True` is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    205\u001b[0m         example_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environment \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mflwr.simulation.run_simulationt(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 211\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexit_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEventType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPYTHON_API_RUN_SIMULATION_LEAVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/simulation/run_simulation.py:510\u001b[0m, in \u001b[0;36m_run_simulation\u001b[0;34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m asyncio_loop_running:\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m         logger \u001b[38;5;241m=\u001b[39m set_logger_propagation(logger, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 510\u001b[0m     updated_context \u001b[38;5;241m=\u001b[39m \u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ths_dev/lib/python3.10/site-packages/flwr/simulation/run_simulation.py:408\u001b[0m, in \u001b[0;36m_main_loop\u001b[0;34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[0m\n\u001b[1;32m    406\u001b[0m         serverapp_th\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m server_app_thread_has_exception\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 408\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException in ServerApp thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    410\u001b[0m log(DEBUG, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping Simulation Engine now.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "# Initiate the simulation passing the server and client apps\n",
    "# Specify the number of super nodes that will be selected on every round\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=3,\n",
    "    #backend_config=backend_setup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ths_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
